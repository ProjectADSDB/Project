{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11eDIg2PKiWkQIx7XvjAGKAAJBStG58Zf","timestamp":1697904751349},{"file_id":"1pq7DliJD3F64lKjBKAo-Pu10mvtdJHhP","timestamp":1697804814415}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Build relational model based on data from persistent zone"],"metadata":{"id":"nh3F3dUSF4u9"}},{"cell_type":"code","source":["# Required libraries\n","import os\n","import pandas as pd\n","import psycopg2\n","import shutil\n","\n","\n","\n","# Constants\n","TEMPORAL_PATH = \"/content/drive/MyDrive/ADSDB/landing/temporal\"\n","PERSISTENT_PATH = \"/content/drive/MyDrive/ADSDB/landing/persistent\"\n","SQL_PATH = \"/content/drive/MyDrive/ADSDB/formatted/sql\"\n","INFLATION_FILENAME = \"inflation_rate\"\n","EMPLOYMENT_FILENAME = \"employment_rate\"\n","HPI_FILENAME = \"house_price_index\"\n","HPI_WEIGHTS_FILENAME = \"house_price_index_weights\"\n","FILENAMES = [INFLATION_FILENAME, EMPLOYMENT_FILENAME, HPI_FILENAME, HPI_WEIGHTS_FILENAME]\n","\n","# Mount Google Drive to Colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#Install PostgreSQL\n","!apt-get -y -qq install postgresql postgresql-contrib &> /dev/null\n","!service postgresql start\n","!sudo -u postgres createuser --superuser adsdb\n","!sudo -u postgres createdb adsdb\n","!sudo -u postgres psql -c \"ALTER USER adsdb WITH PASSWORD 'adsdb';\"\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CvNYuamnKZK1","executionInfo":{"status":"ok","timestamp":1702639263157,"user_tz":-60,"elapsed":46235,"user":{"displayName":"Riccardo Paciello","userId":"06864587933562229020"}},"outputId":"81fa8d10-f2ca-43dc-f192-3c2f4c57ffe1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"," * Starting PostgreSQL 14 database server\n","   ...done.\n","ALTER ROLE\n"]}]},{"cell_type":"code","source":["# Database connection function\n","def connect_to_database():\n","    connection = psycopg2.connect(\n","      host=\"localhost\",\n","      database=\"adsdb\",\n","      user=\"adsdb\",\n","      password=\"adsdb\"\n","    )\n","    return connection.cursor(), connection\n","\n","# Reading a CSV from persistent folder\n","def read_persistent_csv(year, filename):\n","    return pd.read_csv(f\"{PERSISTENT_PATH}/{year}/{filename}_{year}.csv\")\n","\n","# Predefined structures to identify primary keys and any SERIAL columns\n","TABLE_STRUCTURES = {\n","    \"inflation_rate\": {\n","        \"primary_key\": \"year\",\n","    },\n","    \"employment_rate\": {\n","        \"primary_key\": \"id\",\n","        \"serials\": [\"id\"]\n","    },\n","    \"house_price_index\": {\n","        \"primary_key\": \"id\",\n","        \"serials\": [\"id\"]\n","    },\n","    \"house_price_index_weights\": {\n","        \"primary_key\": \"id\",\n","        \"serials\": [\"id\"]\n","    }\n","}\n","\n","def generate_sql_create_table(df, table_name, year):\n","    dtype_mapping = {\n","        'int64': 'INT',\n","        'float64': 'DECIMAL(5,2)',\n","        'object': 'VARCHAR(100)'  # This sets VARCHAR as default, adjust if necessary\n","    }\n","    structures = TABLE_STRUCTURES.get(table_name, {})\n","\n","    columns = []\n","\n","    # If table is inflation_rate, set year as primary key\n","    if table_name == \"inflation_rate\":\n","        columns.append(\"year INT PRIMARY KEY\")\n","    # Otherwise, add auto-incremented id as primary key\n","    else:\n","        columns.append(\"id SERIAL PRIMARY KEY\")\n","        if 'year' in df.columns:\n","            columns.append(\"year INT\")\n","\n","    for col in df.columns:\n","        column_type = dtype_mapping[str(df[col].dtype)]\n","\n","        # Avoid re-adding the column if it's already added as a primary key or year\n","        if col in [\"id\", \"year\"]:\n","            continue\n","\n","        columns.append(f\"{col} {column_type}\")\n","\n","    # If another primary key is defined (besides year or id), create a unique constraint for it\n","    if \"primary_key\" in structures and structures[\"primary_key\"] not in [\"id\", \"year\"]:\n","        columns.append(f\"UNIQUE ({structures['primary_key']})\")\n","\n","    final_table_name = f\"{table_name}_{year}\"\n","    sql_command = f\"CREATE TABLE {final_table_name} ({', '.join(columns)});\"\n","\n","    return sql_command\n","\n","\n","# Save SQL Create Table command to a file\n","def save_sql_to_file(sql_command, filename):\n","    if not os.path.exists(SQL_PATH):\n","        os.makedirs(SQL_PATH)\n","    with open(f\"{SQL_PATH}/{filename}.sql\", 'w') as file:\n","        file.write(sql_command)\n","\n","def store_data_in_postgres(df, table_name, year, cursor, connection):\n","    final_table_name = f\"{table_name}_{year}\"\n","    df_columns = list(df)\n","    columns = \",\".join(df_columns)\n","    values = \"VALUES({})\".format(\",\".join([\"%s\" for _ in df_columns]))\n","\n","    updates = \",\".join([f\"{col}=EXCLUDED.{col}\" for col in df_columns if col not in [\"id\", \"year\"]])\n","    insert_stmt = f\"\"\"\n","        INSERT INTO {final_table_name} ({columns}) {values}\n","        ON CONFLICT ({TABLE_STRUCTURES[table_name]['primary_key']})\n","        DO UPDATE SET {updates}\n","    \"\"\"\n","\n","    try:\n","        cursor.executemany(insert_stmt, df.values)\n","    except Exception as e:\n","        print(f\"Error inserting into table {final_table_name}: {e}\")\n","        connection.rollback()  # Rollback changes in case of error\n","    else:\n","        connection.commit()\n","\n"],"metadata":{"id":"OhY7QcPXND9B","executionInfo":{"status":"ok","timestamp":1702639263158,"user_tz":-60,"elapsed":12,"user":{"displayName":"Riccardo Paciello","userId":"06864587933562229020"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def list_tables(cursor):\n","    cursor.execute(\"\"\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';\"\"\")\n","    tables = [t[0] for t in cursor.fetchall()]\n","    print(f\"In total, we have {len(tables)} tables in the 'adsdb' database.\")\n","    return tables\n","\n","def table_stats(cursor, tablename):\n","    # Fetch the number of rows in the table\n","    cursor.execute(f\"SELECT COUNT(*) FROM {tablename};\")\n","    num_rows = cursor.fetchone()[0]\n","\n","    # Fetch the number of columns in the table\n","    cursor.execute(f\"SELECT COUNT(*) FROM information_schema.columns WHERE table_name = '{tablename}';\")\n","    num_columns = cursor.fetchone()[0]\n","\n","    # Fetch the \"head\" of the table (first 5 rows as an example)\n","    cursor.execute(f\"SELECT * FROM {tablename} LIMIT 5;\")\n","    head_rows = cursor.fetchall()\n","    cursor.execute(f\"SELECT column_name FROM information_schema.columns WHERE table_name = '{tablename}';\")\n","    columns = [col[0] for col in cursor.fetchall()]\n","\n","    table_head = pd.DataFrame(head_rows, columns=columns)\n","\n","    return {\n","        \"table\": tablename,\n","        \"num_rows\": num_rows,\n","        \"num_columns\": num_columns,\n","        \"head\": table_head\n","    }\n","\n","\n","def save_to_drive(dump_path, drive_path):\n","    try:\n","        # Try to copy the dump file to the specified drive path\n","        shutil.copy(dump_path, drive_path)\n","        # Remove the original dump file after copying\n","        os.remove(dump_path)\n","    except Exception as e:\n","        print(f\"Error saving to Google Drive: {e}\")\n","\n","\n"],"metadata":{"id":"TyLdpgRjR0ah","executionInfo":{"status":"ok","timestamp":1702639263158,"user_tz":-60,"elapsed":8,"user":{"displayName":"Riccardo Paciello","userId":"06864587933562229020"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def main():\n","    cursor, connection = connect_to_database()\n","\n","    for filename in FILENAMES:\n","        years = [folder for folder in os.listdir(PERSISTENT_PATH) if folder.isdigit()]\n","        for year in years:\n","            df = read_persistent_csv(year, filename)\n","\n","            # Generate SQL table creation command with year-specific name\n","            sql_command = generate_sql_create_table(df, filename, year)\n","\n","            # Save to file (only once for each data source, not for each year)\n","            if year == years[0]:\n","                save_sql_to_file(sql_command, filename)\n","\n","            final_table_name = f\"{filename}_{year}\"\n","\n","            # Create the table in PostgreSQL (only if the table doesn't exist)\n","            cursor.execute(f\"SELECT to_regclass('{final_table_name}');\")\n","            if cursor.fetchone()[0] is None:\n","                try:\n","                    cursor.execute(sql_command)\n","                except Exception as e:\n","                    print(f\"Error creating table {final_table_name}: {e}\")\n","                    continue  # Skip to the next iteration if there's an error\n","\n","            store_data_in_postgres(df, filename, year, cursor, connection)\n","\n","    # List tables\n","    tables = list_tables(cursor)\n","\n","    # Collect and display statistics for each table\n","    for tablename in tables:\n","        stats = table_stats(cursor, tablename)\n","        print(f\"\\nStatistics for table {tablename}:\")\n","        print(f\"Number of rows: {stats['num_rows']}\")\n","        print(f\"Number of columns: {stats['num_columns']}\")\n","        print(\"Head of the table:\")\n","        print(stats['head'])\n","        print(\"-\" * 50)  # Separator\n","\n","    # Path for the dump file\n","    dump_path = \"/content/dumpfile.sql\"\n","    drive_path = \"/content/drive/MyDrive/ADSDB/formatted/dumpfile.sql\"\n","\n","    # Create a temporary .pgpass file for authentication\n","    with open(\"/root/.pgpass\", \"w\") as f:\n","        f.write(\"*:*:*:adsdb:adsdb\")\n","    os.chmod(\"/root/.pgpass\", 0o600)  # Set the required permissions\n","\n","    # Use the pg_dump command to dump the data\n","    try:\n","        !PGPASSFILE=/root/.pgpass pg_dump -h localhost -U adsdb -d adsdb -f \"{dump_path}\"\n","        # If successful, save the dump to Google Drive\n","        save_to_drive(dump_path, drive_path)\n","    except Exception as e:\n","        print(f\"Error during pg_dump: {e}\")\n","\n","    # Clean up the temporary password file\n","    os.remove(\"/root/.pgpass\")\n","\n","\n","    connection.close()\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"WYxEpC0qSnug","colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"status":"error","timestamp":1702639264267,"user_tz":-60,"elapsed":1115,"user":{"displayName":"Riccardo Paciello","userId":"06864587933562229020"}},"outputId":"6fb1c24b-8992-478b-a635-6e7a0e8c4ca4"},"execution_count":4,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-4ad724a24aae>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-4ad724a24aae>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0myears\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPERSISTENT_PATH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_persistent_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# Generate SQL table creation command with year-specific name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-0492c339188f>\u001b[0m in \u001b[0;36mread_persistent_csv\u001b[0;34m(year, filename)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Reading a CSV from persistent folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_persistent_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{PERSISTENT_PATH}/{year}/{filename}_{year}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Predefined structures to identify primary keys and any SERIAL columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ADSDB/landing/persistent/2008/inflation_rate_2008.csv'"]}]}]}